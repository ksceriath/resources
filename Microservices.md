#ArchitecturePatterns 

#### Distributed Logging
##### Log Consolidation
These are things like [[splunk]], [[logstash]], etc, which read log files generated by microservices in a distributed manner, and consolidate all of those into one place.

##### Log Streaming
This is where each microservice pushes its logs in a streaming fashion to [[kafka]] or [[MAPR]] etc, and then different subscribers can be written to perform analytics and extract useful data from there.

##### Steps
1. Have a **request context id(s)** which identify the request
2. Create a **context id hierarchy** ('use this id if another not present', etc)
3. Use an **interceptor** which automatically parses the request payload and extract context information (instead of manually doing it everytime)
	1. if an *api gateway* with code is used in the architecture, that might be a place to do this parsing/extraction as an 'infrastructure concern'
4. Use *context id* in the payload in the communication between the services
	1. if *context id* is found? use that, else use the hierarchy rules to figure it out
5. Optionally use a custom logging wrapper - take a log and put it somewhere.


#Draft 